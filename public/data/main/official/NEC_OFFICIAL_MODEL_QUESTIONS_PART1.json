[
  {
    "id": 1,
    "question": "Decibel relation for power gain is",
    "options": [
      "20 log₁₀(P₂/P₁)",
      "10 log₁₀(P₂/P₁)",
      "20 log₁₀(P₂/P₁) + 10 log₁₀(P₂/P₁)",
      "10 log₁₀(P₁/P₂)"
    ],
    "correct_answer": "10 log₁₀(P₂/P₁)",
    "hint": "Power gain in decibels uses 10 times the logarithm, not 20. Remember: dB = 10 log₁₀(ratio).",
    "explanation": "The decibel relation for power gain is defined as: dB = 10 log₁₀(P₂/P₁), where P₂ is final power and P₁ is initial power. This formula specifically applies to power ratios. The factor of 20 is used only for voltage or current ratios (20 log₁₀(V₂/V₁)), not for power. Since power is proportional to voltage squared, the 20 factor for voltage translates to 10 for power. This is a fundamental concept in electrical engineering and signal processing.",
    "chapter": "Chapter 1: Electrical & Electronics",
    "difficulty": "easy",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 2,
    "question": "Maximum power that can be transferred from source to load is",
    "options": ["25%", "75%", "50%", "100%"],
    "correct_answer": "50%",
    "hint": "This relates to Maximum Power Transfer Theorem. When is power transfer maximized?",
    "explanation": "According to the Maximum Power Transfer Theorem, maximum power is transferred from source to load when the load resistance equals the source resistance (RL = Rs). At this condition, exactly 50% of the total power generated by the source is delivered to the load, while the remaining 50% is dissipated in the source resistance. This is a fundamental principle in circuit analysis and ensures optimal power delivery. The efficiency at this point is 50%, though in practical applications, different impedance matching may be desired depending on whether power or efficiency is prioritized.",
    "chapter": "Chapter 1: Electrical & Electronics",
    "difficulty": "easy",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 3,
    "question": "Power factor has maximum value of",
    "options": ["0.0", "0.5", "1.0", "1.5"],
    "correct_answer": "1.0",
    "hint": "Power factor is a ratio between 0 and 1. What does PF = 1 mean?",
    "explanation": "Power factor (PF) is defined as the ratio of real power (P) to apparent power (S): PF = P/S = cos(φ). Since both P and S are positive quantities and P ≤ S, the maximum possible value of power factor is 1.0. This occurs when the load is purely resistive with zero reactive power, meaning voltage and current are in phase (φ = 0°). A power factor of 1.0 indicates 100% efficiency in power usage. Values greater than 1.0 are mathematically impossible. Industrial loads often have PF between 0.7-0.95 due to inductive components.",
    "chapter": "Chapter 1: Electrical & Electronics",
    "difficulty": "easy",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 4,
    "question": "EEPROM has drain and floating gate gap of",
    "options": ["5 nm", "10 nm", "12 nm", "15 nm"],
    "correct_answer": "10 nm",
    "hint": "Standard EEPROM device specifications for oxide layer thickness.",
    "explanation": "EEPROM (Electrically Erasable Programmable Read-Only Memory) devices have a characteristic oxide layer (tunnel oxide) between the drain and floating gate with a typical thickness of approximately 10 nanometers. This oxide layer is crucial for the device's operation as it controls electron tunneling for programming and erasing operations. The thickness affects the voltage required for writing/erasing and the data retention characteristics. Modern flash memory devices may have variations in this specification, but for standard EEPROM, 10 nm is the reference value. This thin oxide layer is critical for achieving the low voltages required for EEPROM operation.",
    "chapter": "Chapter 1: Electrical & Electronics",
    "difficulty": "medium",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 5,
    "question": "Heisenberg principle of uncertainty says",
    "options": [
      "Signal of 10Hz can be generated",
      "Signal of 10MHz can be generated",
      "Signal of 100MHz can be generated",
      "Signal of band 100MHz-105MHz can be generated"
    ],
    "correct_answer": "Signal of band 100MHz-105MHz can be generated",
    "hint": "Heisenberg's uncertainty principle relates to the relationship between time and frequency resolution. The smaller the time window, the larger the frequency spread.",
    "explanation": "Heisenberg's uncertainty principle states that there is a fundamental limit on the precision with which certain pairs of physical properties can be known. In signal processing terms, it means: Δt × Δf ≥ 1/(4π), where Δt is time resolution and Δf is frequency resolution. A signal generated in a specific time window must occupy a certain bandwidth. A signal with a 5 MHz bandwidth (100MHz-105MHz) is achievable because it respects the uncertainty principle. A pure single frequency like 10Hz, 10MHz, or 100MHz would require infinite time duration to generate, which is practically impossible. The uncertainty principle prevents the generation of perfectly defined single-frequency signals of finite duration.",
    "chapter": "Chapter 1: Electrical & Electronics",
    "difficulty": "difficult",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 6,
    "question": "UHF frequency signal can be amplified using",
    "options": [
      "Class A amplifier",
      "Class AB amplifier",
      "Class C amplifier",
      "Class B amplifier"
    ],
    "correct_answer": "Class C amplifier",
    "hint": "Class C amplifiers are designed for high-frequency applications. Which class has the highest efficiency but narrowest bandwidth?",
    "explanation": "Class C amplifiers are specifically designed for amplifying high-frequency RF (Radio Frequency) and UHF (Ultra High Frequency) signals. Class C amplifiers have transistors conducting for less than 180° of the input cycle, making them highly efficient (up to 80-90%) but producing significant harmonic content. They require tuned loads to filter out harmonics. UHF frequencies (300 MHz to 3 GHz) require Class C because: (1) They provide high efficiency at high frequencies, (2) Their narrow bandwidth design matches RF frequencies, (3) They handle the switching speeds required. Class A and AB are linear but inefficient at high frequencies. Class B is better for audio but not optimal for UHF. The tuned tank circuit in Class C naturally rejects harmonics at UHF frequencies.",
    "chapter": "Chapter 1: Electrical & Electronics",
    "difficulty": "medium",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 7,
    "question": "Two's complement of 00011011 is",
    "options": ["11100100", "11100101", "11000101", "11110001"],
    "correct_answer": "11100101",
    "hint": "Two's complement = One's complement + 1. First invert all bits, then add 1.",
    "explanation": "To find the two's complement of a binary number, follow these steps: (1) Find the one's complement by inverting all bits: 00011011 → 11100100, (2) Add 1 to the result: 11100100 + 1 = 11100101. Two's complement is the standard method for representing negative numbers in binary. It provides a single representation for zero and simplifies arithmetic operations. For 00011011 (which is +27 in decimal), the two's complement 11100101 represents -27 in an 8-bit signed system. This method eliminates the problem of having two representations for zero and makes subtraction equivalent to addition of the two's complement, simplifying CPU design.",
    "chapter": "Chapter 2: Digital Logic & Microprocessor",
    "difficulty": "easy",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 8,
    "question": "Elementary building block of combinational circuit is",
    "options": [
      "Logic gate",
      "Flip-flop",
      "Both logic gate and flip-flop",
      "Memory"
    ],
    "correct_answer": "Logic gate",
    "hint": "Combinational circuits produce outputs based only on current inputs, not on state. What has no memory?",
    "explanation": "Logic gates (AND, OR, NOT, NAND, NOR, XOR) are the elementary building blocks of combinational circuits. Combinational circuits are circuits where the output depends only on the current inputs, not on previous states or history. Logic gates implement basic Boolean functions and can be combined to create more complex combinational circuits like adders, multiplexers, and decoders. Flip-flops introduce memory (state) and are used in sequential circuits, not combinational circuits. Memory elements like flip-flops create feedback loops that make circuits sequential. Pure combinational logic has no feedback, no state, and no memory. All combinational circuits can be constructed using logic gates and the Boolean algebra they implement.",
    "chapter": "Chapter 2: Digital Logic & Microprocessor",
    "difficulty": "easy",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 9,
    "question": "Synchronous circuit that changes its state at specific clock signal is",
    "options": [
      "Event driven",
      "Clock driven",
      "Pulse driven",
      "Frequency driven"
    ],
    "correct_answer": "Clock driven",
    "hint": "Synchronous means coordinated with a clock signal. What term describes this timing mechanism?",
    "explanation": "Synchronous circuits are clock-driven circuits where all state changes occur at specific moments synchronized with a clock signal. The clock signal provides timing pulses that coordinate the operation of all sequential elements in the circuit. All flip-flops and state machines change states on the rising or falling edge of the clock pulse, ensuring orderly operation and preventing race conditions. This is in contrast to asynchronous circuits which are event-driven and change states based on input changes whenever they occur. Clock-driven synchronous design is the standard in modern digital systems because it: (1) Prevents race conditions, (2) Provides predictable timing, (3) Simplifies verification and debugging, (4) Enables high-speed operation.",
    "chapter": "Chapter 2: Digital Logic & Microprocessor",
    "difficulty": "easy",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 10,
    "question": "Bandwidth of microprocessor represents",
    "options": [
      "Clock speed",
      "Width of internal bus",
      "Number of bits processed per instruction",
      "Number of bits processed per second"
    ],
    "correct_answer": "Width of internal bus",
    "hint": "In processor terminology, bandwidth refers to the data width, not frequency. What determines how many bits can be moved at once?",
    "explanation": "In microprocessor terminology, bandwidth refers to the width of the internal bus (data bus) in bits. This indicates how many bits of data can be transferred simultaneously within the processor. For example, an 8-bit microprocessor has an 8-bit data bus bandwidth, a 32-bit processor has 32-bit bandwidth. This is different from (1) Clock speed, which measures frequency in Hz, (2) Instruction throughput, which is bits per instruction, or (3) Data transfer rate, which is bits per second. The bus width directly affects the amount of data that can be processed in one clock cycle. A wider bus means more data can be moved, potentially improving performance. This is a fundamental characteristic distinguishing processor generations (8-bit, 16-bit, 32-bit, 64-bit processors).",
    "chapter": "Chapter 2: Digital Logic & Microprocessor",
    "difficulty": "medium",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 11,
    "question": "PPI 8255 has internal bus of size",
    "options": ["4 bit", "8 bit", "16 bit", "32 bit"],
    "correct_answer": "8 bit",
    "hint": "The 8255 is an 8-bit peripheral device from the 1980s era. What is the standard bus width for such devices?",
    "explanation": "The Intel 8255 Programmable Peripheral Interface has an internal 8-bit data bus. The 8255 is an important I/O controller used with 8-bit microprocessors like the 8085 and 8086. It features: (1) Three 8-bit ports (Port A, Port B, Port C), (2) Programmable control logic, (3) 8-bit internal data bus for communication with the CPU, (4) Various operating modes for input/output operations. The 8-bit bus width matches the data bus of the microprocessors of its era. Each port can transfer 8 bits of data. The internal bus width determines how much data can be transferred in one operation. Despite modern systems using wider buses, the 8255 remains important in embedded systems and industrial applications.",
    "chapter": "Chapter 2: Digital Logic & Microprocessor",
    "difficulty": "easy",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 12,
    "question": "Interrupt Service Routine (ISR) executes",
    "options": [
      "Before execution of current instructions",
      "With pause of current instructions",
      "After execution of current instructions",
      "With execution of no instruction"
    ],
    "correct_answer": "After execution of current instructions",
    "hint": "An interrupt doesn't interrupt mid-instruction. The processor finishes the current instruction first.",
    "explanation": "An Interrupt Service Routine (ISR) executes after the current instruction completes execution. When an interrupt occurs: (1) The processor finishes executing the current instruction, (2) The processor saves the current state (program counter and registers), (3) The processor jumps to the ISR address, (4) The ISR executes completely, (5) Upon returning from ISR, execution resumes from where it was interrupted. This ensures that instructions are atomic and not interrupted mid-execution, preventing data corruption. The processor cannot execute an ISR with a pause in the middle of an instruction as that would violate instruction atomicity. The phrase 'after execution of current instructions' acknowledges that the current instruction must complete before the ISR begins. Different ISR priorities may exist, with higher priority interrupts able to interrupt lower priority ISRs.",
    "chapter": "Chapter 2: Digital Logic & Microprocessor",
    "difficulty": "medium",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 13,
    "question": "Which of the following is not a data type in C?",
    "options": ["int", "float", "String", "char"],
    "correct_answer": "String",
    "hint": "C has primitive data types. String is a construct, not a built-in primitive type.",
    "explanation": "In C, 'String' is not a built-in data type. The primitive data types in C are: (1) int (integers), (2) float (floating-point numbers), (3) char (single characters), (4) double (double-precision floating-point), (5) void. Strings in C are represented as arrays of characters (char arrays), not as a primitive type. For example: char str[] = \"Hello\"; creates a string. Unlike languages such as Java or Python that have a String class, C does not have a native string type. Strings are created using null-terminated char arrays. C provides string handling functions in the standard library (string.h) like strlen(), strcpy(), etc., but these work with char arrays, not a built-in String type. This is an important distinction for C programmers.",
    "chapter": "Chapter 3: Programming Languages",
    "difficulty": "easy",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 14,
    "question": "What is the size of a pointer in C?",
    "options": [
      "1 byte",
      "2 bytes",
      "4 bytes",
      "It depends on the system architecture"
    ],
    "correct_answer": "It depends on the system architecture",
    "hint": "Pointer size varies with the operating system and processor architecture. Think about 32-bit vs 64-bit systems.",
    "explanation": "The size of a pointer in C depends on the system architecture. On 32-bit systems, pointers are typically 4 bytes (32 bits), while on 64-bit systems, pointers are typically 8 bytes (64 bits). This is because pointers store memory addresses, and the address space size determines pointer size. A pointer must be large enough to address all available memory. On a 32-bit system with 4 GB maximum addressable memory, 4 bytes (32 bits) are sufficient. On a 64-bit system, 8 bytes are needed for larger address spaces. The size() operator can determine pointer size: printf(\"%zu\", sizeof(int*)); typically outputs 4 (on 32-bit) or 8 (on 64-bit). Specialized architectures may use different pointer sizes. This architecture-dependence is important when writing portable C code.",
    "chapter": "Chapter 3: Programming Languages",
    "difficulty": "medium",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 15,
    "question": "Which access specifier is used to make the members of a class accessible only within the same class?",
    "options": ["public", "private", "protected", "public and protected"],
    "correct_answer": "private",
    "hint": "Private members cannot be accessed from outside the class or even from derived classes.",
    "explanation": "The 'private' access specifier restricts access to class members strictly to within the same class only. Private members: (1) Cannot be accessed from outside the class, (2) Cannot be accessed from derived classes, (3) Cannot be accessed by friend functions (unless explicitly declared as friends), (4) Provide encapsulation and data hiding. Public members are accessible from anywhere. Protected members are accessible within the class and derived classes. The private specifier is fundamental to object-oriented programming's encapsulation principle - hiding internal implementation details. For example: class MyClass { private: int x; // Only accessible within MyClass }; Attempting to access private members from outside the class results in compilation errors. This enforces data abstraction and prevents unintended modifications to internal state.",
    "chapter": "Chapter 3: Programming Languages",
    "difficulty": "easy",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 16,
    "question": "What is operator overloading in C++?",
    "options": [
      "Defining a new operator",
      "Overriding an existing operator",
      "Changing the behaviour of an existing operator",
      "Changing the behaviour of new operator"
    ],
    "correct_answer": "Changing the behaviour of an existing operator",
    "hint": "Overloading modifies how an existing operator works with different data types.",
    "explanation": "Operator overloading in C++ is the ability to redefine how existing operators (+, -, *, /, ==, etc.) work with user-defined types (classes). You cannot define entirely new operators (option 1 and 4 are incorrect). You don't simply override existing operators without a context (that's not what overloading means). Instead, operator overloading allows you to change the behavior of an existing operator to work with your custom classes. For example: class Complex { public: Complex operator+(const Complex& other) { ... } }; This redefines the '+' operator for Complex numbers. Benefits of operator overloading: (1) Makes code more intuitive and readable, (2) Allows natural syntax for custom types, (3) Maintains consistency with built-in types. Restrictions: Cannot overload (::, ., .*, ?:), must overload as member function (=, [], (), ->), cannot change operator precedence or associativity.",
    "chapter": "Chapter 3: Programming Languages",
    "difficulty": "medium",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 17,
    "question": "What is the difference between ifstream and ofstream in C++?",
    "options": [
      "ifstream is used for input, while ofstream is used for output",
      "ofstream is used for input, while ifstream is used for output",
      "both are used as input",
      "both are used as output"
    ],
    "correct_answer": "ifstream is used for input, while ofstream is used for output",
    "hint": "'i' = input, 'o' = output. The prefix clearly indicates the direction of data flow.",
    "explanation": "In C++, ifstream and ofstream are file stream classes from the <fstream> library: (1) ifstream (input file stream) - Used for reading data from files. Opens files in input mode by default. (2) ofstream (output file stream) - Used for writing data to files. Opens files in output mode by default. Additional file stream classes: (3) fstream - Can be used for both input and output operations, requiring explicit specification of mode. Usage examples: ifstream infile(\"input.txt\"); // Opens for reading, ofstream outfile(\"output.txt\"); // Opens for writing. These classes inherit from basic_istream and basic_ostream respectively. They automatically handle file opening and closing (destructor closes file). They support operators (>> for input, << for output) making file I/O similar to console I/O. Using the appropriate stream class improves code clarity and prevents accidental operations on files.",
    "chapter": "Chapter 3: Programming Languages",
    "difficulty": "easy",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 18,
    "question": "What is a class template in C++?",
    "options": [
      "A class that can be used to create objects of different types",
      "A function that can be used to create objects of different types",
      "A variable that can be used to create objects of different types",
      "A character that can be used to create objects of different types"
    ],
    "correct_answer": "A class that can be used to create objects of different types",
    "hint": "Templates enable generic programming. A template class can work with any data type.",
    "explanation": "A class template in C++ is a blueprint for creating classes that can work with any data type. It allows you to define a generic class where the data type is parameterized. Key concepts: (1) Templates use template parameters (usually template<typename T>), (2) You can use the parameter T as any data type within the class, (3) Instantiation creates specific classes for each data type used. Example: template<typename T> class Stack { private: T data[100]; }; This creates a Stack that works with any type. Usage: Stack<int> intStack; Stack<double> doubleStack; Both are created from the same template. Benefits: (1) Code reusability across different data types, (2) Type safety (templates are type-checked at compile time), (3) No runtime overhead. Class templates are fundamental to the Standard Template Library (STL) which provides containers like vector, list, map using templates. This differs from function templates (which template functions) or variable templates (C++14).",
    "chapter": "Chapter 3: Programming Languages",
    "difficulty": "medium",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 19,
    "question": "What is the purpose of the control unit in a CPU?",
    "options": [
      "To perform arithmetic and logical operations on data",
      "To store and retrieve data from memory",
      "To interpret instructions and control the flow of data within the CPU",
      "To print data from memory"
    ],
    "correct_answer": "To interpret instructions and control the flow of data within the CPU",
    "hint": "The control unit orchestrates CPU operations. What coordinates all the different parts?",
    "explanation": "The control unit's primary purpose is to interpret instructions and control the flow of data within the CPU. Specifically, it: (1) Fetches instructions from memory, (2) Decodes the instruction to determine what operation is needed, (3) Sends control signals to other CPU components to execute the instruction, (4) Manages the instruction sequence and program counter, (5) Coordinates timing and synchronization. The control unit directs: (1) The ALU (Arithmetic Logic Unit) - which performs arithmetic and logical operations, (2) Memory operations - for storing and retrieving data, (3) Register operations - for data movement and storage. Think of the control unit as the 'traffic controller' of the CPU. Other components have specific functions: the ALU performs calculations, registers store data, memory stores programs and data. But the control unit orchestrates how all these parts work together. Without the control unit, the CPU would be like an orchestra without a conductor - individual instruments working but not in harmony. The control unit implements the fetch-decode-execute cycle.",
    "chapter": "Chapter 4: Computer Organization",
    "difficulty": "easy",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 20,
    "question": "What is the purpose of the cache replacement policy?",
    "options": [
      "To determine which data to store in the cache",
      "To determine which data to evict from the cache when space is needed",
      "To determine how many levels of cache to use",
      "To determine which data to store in RAM"
    ],
    "correct_answer": "To determine which data to evict from the cache when space is needed",
    "hint": "When cache is full, what policy decides which existing data gets removed?",
    "explanation": "Cache replacement policy determines which data block to evict (remove) from the cache when new data needs to be stored and the cache is full. Common replacement policies: (1) Least Recently Used (LRU) - Removes the block that hasn't been used recently, (2) First-In-First-Out (FIFO) - Removes the oldest block, (3) Least Frequently Used (LFU) - Removes the least frequently accessed block, (4) Random replacement - Randomly selects a block. The effectiveness of a replacement policy impacts cache performance: A good policy ensures frequently accessed data stays in cache, improving hit rate and performance. A poor policy might evict data that's needed again soon, causing cache misses. LRU is widely used because it performs well in practice - data recently accessed is likely needed again soon. Selection criteria: (1) Minimize cache misses, (2) Keep frequently used data in cache, (3) Maximize overall system performance. This is different from deciding what data to initially cache (which is determined by cache coherence and write policies) or determining cache structure (number of levels, size).",
    "chapter": "Chapter 4: Computer Organization",
    "difficulty": "medium",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 21,
    "question": "Which of the following is not a type of DMA transfer mode?",
    "options": [
      "Burst mode",
      "Cycle-stealing mode",
      "Interrupt mode",
      "Instruction mode"
    ],
    "correct_answer": "Instruction mode",
    "hint": "DMA operates in specific modes for data transfer. Which one is not a recognized DMA mode?",
    "explanation": "DMA (Direct Memory Access) has three main transfer modes: (1) Burst mode - The DMA controller takes complete control of the system bus and transfers a block of data in one continuous operation. Maximum throughput but may delay CPU. (2) Cycle-stealing mode - The DMA controller steals CPU cycles to transfer one byte/word at a time, reducing impact on CPU but taking more total time. (3) Transparent mode - Transfers occur only when the bus is idle, not affecting CPU at all (rarely used). 'Instruction mode' is NOT a recognized DMA transfer mode. DMA operates independently of instructions - it doesn't execute instructions. Options for DMA operations: (1) By channel - Multiple DMA channels for different devices, (2) By priority - Higher priority devices get preference, (3) By rotation - Fair sharing among devices. 'Interrupt mode' mentioned in some contexts refers to when DMA signals completion via interrupt, but it's not a transfer mode itself - it's a signaling mechanism. Understanding these modes is important for systems design, particularly in embedded systems and I/O-intensive applications.",
    "chapter": "Chapter 4: Computer Organization",
    "difficulty": "medium",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 22,
    "question": "An instruction set refers to",
    "options": [
      "set of rules for writing code in a specific programming language",
      "instructions that a processor can execute",
      "input-output operations that a processor can perform",
      "printing commands"
    ],
    "correct_answer": "instructions that a processor can execute",
    "hint": "Instruction set is hardware-level. What does a processor directly understand?",
    "explanation": "An instruction set refers to the complete set of machine instructions that a processor can execute. It's the basic instruction set that the CPU natively understands and can perform. Each instruction set is processor-specific and includes: (1) Arithmetic operations (ADD, SUB, MUL, DIV), (2) Logical operations (AND, OR, XOR, NOT), (3) Memory operations (LOAD, STORE), (4) Control flow (JUMP, CALL, RETURN), (5) I/O operations (INPUT, OUTPUT). Examples of instruction sets: (1) x86/x86-64 (Intel/AMD processors), (2) ARM (mobile processors), (3) RISC-V (open standard), (4) MIPS. Characteristics: (1) Processor-specific - Different processors have different instruction sets, (2) Machine-level - In binary or assembly form, (3) Hardware implementation - Directly executed by CPU circuits. This is different from: (1) Programming language syntax - which is a higher-level abstraction, (2) I/O operations - which are part of but not the entirety of instruction set, (3) Printing commands - which don't constitute an instruction set. The instruction set defines what a processor can do at the most fundamental level.",
    "chapter": "Chapter 4: Computer Organization",
    "difficulty": "easy",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 23,
    "question": "What is a real-time kernel?",
    "options": [
      "The core component of a real-time operating system",
      "The user interface of a real-time operating system",
      "The hardware component of a real-time operating system",
      "The core component of a real-time pointer system"
    ],
    "correct_answer": "The core component of a real-time operating system",
    "hint": "Kernel is the core of any OS. What does 'real-time' mean it must do?",
    "explanation": "A real-time kernel is the core component of a real-time operating system (RTOS). It manages resources and task scheduling with strict timing constraints. Characteristics of a real-time kernel: (1) Deterministic behavior - Response times are predictable and bounded, (2) Priority-based scheduling - Tasks are scheduled by priority, high-priority tasks preempt low-priority ones, (3) Preemption - Can interrupt lower-priority tasks to serve urgent ones, (4) Low latency - Minimal delay between interrupt and response. Real-time kernels are used in: (1) Embedded systems - Industrial controllers, medical devices, automotive systems, (2) Time-critical applications - Flight control, power plants, robotics. Distinction from general-purpose kernels: (1) General-purpose kernels optimize for throughput and fairness, (2) Real-time kernels optimize for meeting deadlines. Types: (1) Hard real-time - Missing deadline is unacceptable (aircraft systems), (2) Soft real-time - Missing deadline is undesirable but tolerable (multimedia). The kernel's job is to enforce timing guarantees for all tasks in the system. Examples: VxWorks, QNX Neutrino, FreeRTOS.",
    "chapter": "Chapter 4: Computer Organization",
    "difficulty": "medium",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 24,
    "question": "What is a signal in VHDL?",
    "options": [
      "A variable used to store a value in a digital circuit",
      "A physical wire used to transmit data in a digital circuit",
      "A function used to perform a specific task in VHDL",
      "A file used to store a specific task"
    ],
    "correct_answer": "A physical wire used to transmit data in a digital circuit",
    "hint": "Signals in VHDL represent the wires connecting components. What do wires do in circuits?",
    "explanation": "In VHDL (Very High Speed Integrated Circuit Hardware Description Language), a signal represents a physical wire used to transmit data between components in a digital circuit. Signals are fundamental building blocks in VHDL: (1) Carry values of specific types (bit, bit_vector, std_logic, etc.), (2) Connect different components of the design, (3) Have propagation delays in simulation, (4) Update at specific times determined by the simulator. Key differences from variables: (1) Variables are used within processes, updating immediately, (2) Signals are global to the design, updating at end of time step, (3) Signals model hardware wires, variables model software concepts. Signal declaration: signal wire_name : std_logic; signal bus : std_logic_vector(7 downto 0); Signal assignment: wire_name <= source_value; Bus signals can carry multiple bits (buses), similar to real circuit buses. Signals include: (1) Input ports - From external circuits, (2) Output ports - To external circuits, (3) Internal signals - Between internal components. This is why VHDL is suitable for hardware design - signals naturally model the wires in physical circuits.",
    "chapter": "Chapter 5: Network & Security",
    "difficulty": "medium",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 25,
    "question": "Which of the following is an example of a physical layer protocol?",
    "options": ["Ethernet", "TCP", "HTTP", "ISP"],
    "correct_answer": "Ethernet",
    "hint": "Physical layer protocols deal with actual transmission media and raw bits. Which operates at the hardware level?",
    "explanation": "Ethernet is an example of a physical layer protocol (Layer 1 of the OSI model). Ethernet specifies: (1) Physical transmission media (copper cables, fiber optics), (2) Signal encoding (voltage levels, light pulses), (3) Physical connectors (RJ-45, SMA), (4) Transmission rates (10 Mbps, 100 Mbps, 1 Gbps, 10 Gbps), (5) Cable lengths and standards. Physical layer protocols deal with: (1) Bit transmission over physical media, (2) Hardware specifications, (3) Signal propagation. The other options operate at higher layers: (1) TCP - Transport layer (Layer 4), (2) HTTP - Application layer (Layer 7), (3) ISP - Not a protocol; stands for Internet Service Provider. Other physical layer protocols: (1) WiFi (802.11) - Wireless transmission, (2) Bluetooth - Short-range wireless, (3) RS-232/RS-485 - Serial communication. Understanding the OSI layer model helps distinguish protocol types: Layers 1-2 (Physical/Data Link) - Hardware level, Layers 3-4 (Network/Transport) - Routing/end-to-end delivery, Layers 5-7 (Session/Presentation/Application) - Software level. Ethernet remains the most common LAN protocol despite advances.",
    "chapter": "Chapter 5: Network & Security",
    "difficulty": "easy",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 26,
    "question": "The PPP of the OSI model operates at",
    "options": [
      "Physical layer",
      "Data link layer",
      "Network layer",
      "Transport layer"
    ],
    "correct_answer": "Data link layer",
    "hint": "PPP (Point-to-Point Protocol) establishes links between two devices. What layer manages data link establishment?",
    "explanation": "PPP (Point-to-Point Protocol) operates at the Data Link Layer (Layer 2) of the OSI model. PPP is used for: (1) Establishing direct point-to-point connections between two devices, (2) Dial-up connections (historically common), (3) Serial links between routers, (4) Authentication (PAP, CHAP), (5) Network configuration (IP address negotiation). Data link layer functions: (1) Frame formation and transmission, (2) Error detection, (3) Access control to shared media, (4) MAC addressing. PPP features: (1) Encapsulates network-layer protocols (IP, IPX, NetBEUI), (2) Provides authentication mechanisms, (3) Compression capabilities, (4) Error checking, (5) Link quality monitoring. Protocol stack for PPP connection: (1) Physical layer - Actual modem or serial line, (2) Data Link layer - PPP framing and protocol (3) Network layer - IP or other network protocol, (4) Higher layers - TCP, UDP, applications. Modern alternatives to PPP: (1) PPPoE (PPP over Ethernet), (2) L2TP (Layer 2 Tunneling Protocol), (3) Direct Ethernet connections. PPP remains important in legacy systems and specialized applications.",
    "chapter": "Chapter 5: Network & Security",
    "difficulty": "medium",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 27,
    "question": "Which of the following is a type of routing algorithm used in the network layer?",
    "options": [
      "Link-state routing",
      "Distance-vector routing",
      "Path-vector routing",
      "All of the above"
    ],
    "correct_answer": "All of the above",
    "hint": "Network layer uses multiple routing approaches. Are all three types actually used?",
    "explanation": "All three routing algorithms (link-state, distance-vector, and path-vector) are used in the network layer. Each has different characteristics: (1) Distance-Vector Routing - Routes based on number of hops (hop count as metric). Examples: RIP (Routing Information Protocol). Each router knows only its neighbors and distances. Slow convergence but simple. (2) Link-State Routing - Each router knows complete network topology. Uses Dijkstra's algorithm. Examples: OSPF (Open Shortest Path First), IS-IS. Faster convergence, more overhead. (3) Path-Vector Routing - Maintains entire path to destination, not just hop count. Examples: BGP (Border Gateway Protocol). Used for inter-AS (Autonomous System) routing. Provides loop prevention through path tracking. Selection depends on: (1) Network size and topology, (2) Convergence requirements, (3) Bandwidth constraints, (4) Scalability needs. Modern networks often use combinations: Interior routing (OSPF within organization), Exterior routing (BGP between organizations). Each algorithm has trade-offs in complexity, overhead, and convergence time. These are fundamental concepts in network design.",
    "chapter": "Chapter 5: Network & Security",
    "difficulty": "medium",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 28,
    "question": "Which protocol is responsible for error detection and correction at the transport layer?",
    "options": ["TCP", "UDP", "ICMP", "ARP"],
    "correct_answer": "TCP",
    "hint": "Which transport protocol ensures reliable delivery? Which one is connectionless and unreliable?",
    "explanation": "TCP (Transmission Control Protocol) is responsible for error detection and correction at the transport layer (Layer 4). TCP provides: (1) Error detection - Checksums detect corruption, (2) Error correction - Retransmission of lost/corrupted packets, (3) Sequence numbers - Track packet order, (4) Acknowledgments - Confirm successful delivery, (5) Flow control - Prevent sender overwhelming receiver, (6) Connection management - Established connection before data transfer. Other protocols' functions: (1) UDP - No error correction, just error detection (checksum only), best-effort delivery, (2) ICMP - Error reporting and diagnostics (ping, traceroute), (3) ARP - Address resolution (IP to MAC mapping), operates between layers. TCP reliability mechanisms: (1) Positive acknowledgments - Receiver sends ACK, (2) Timeout and retransmission - Resend if no ACK received, (3) Sequence numbers - Detect duplicates/reordering, (4) Checksums - Detect corruption. Trade-off: TCP has overhead (headers, acknowledgments) but ensures reliability. UDP is faster but unreliable. Applications choosing protocol: (1) TCP for email, web, file transfer (reliability critical), (2) UDP for streaming, gaming, VoIP (speed more important than occasional loss). TCP's reliability comes at a cost - it's slower than UDP.",
    "chapter": "Chapter 5: Network & Security",
    "difficulty": "easy",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 29,
    "question": "Which application layer protocol is used for sending and receiving emails?",
    "options": ["HTTP", "FTP", "SMTP", "POP"],
    "correct_answer": "SMTP",
    "hint": "SMTP is for sending. POP/IMAP are for receiving. This question asks about 'sending and receiving', but specifically look for sending.",
    "explanation": "SMTP (Simple Mail Transfer Protocol) is the application layer protocol used for sending emails. Combined with POP3 or IMAP for receiving: (1) SMTP - Sends emails from client to mail server and between mail servers (Port 25 for relay, 587 for clients), (2) POP3 (Post Office Protocol) - Retrieves emails from server (Port 110), (3) IMAP (Internet Message Access Protocol) - Advanced retrieval with server-side storage (Port 143). Complete email communication: (1) User writes email in mail client, (2) SMTP sends email to sender's mail server, (3) SMTP relays between mail servers, (4) SMTP delivers to recipient's mail server, (5) Recipient uses POP3 or IMAP to retrieve. SMTP features: (1) Text-based protocol (like HTTP), (2) Uses TCP port 25, 587, or 465 (secure), (3) Commands like MAIL FROM, RCPT TO, DATA, (4) Can be secured with STARTTLS or SSL/TLS. Other email protocols: (1) HTTP - Web access to email (Gmail, Outlook web), (2) FTP - File transfer (not email), (3) LDAP - Directory services for email addresses. Modern variations: (1) OAuth for authentication, (2) DKIM/SPF for spam prevention, (3) SMTPS for encrypted transmission. SMTP remains essential for email delivery.",
    "chapter": "Chapter 5: Network & Security",
    "difficulty": "easy",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 30,
    "question": "Which of the following is not a common type of firewall?",
    "options": [
      "Packet-filtering firewall",
      "Stateful inspection firewall",
      "Proxy firewall",
      "Encryption firewall"
    ],
    "correct_answer": "Encryption firewall",
    "hint": "Common firewalls are based on filtering approaches. Is encryption itself a firewall type?",
    "explanation": "Encryption firewall is not a common firewall type. Common firewall types: (1) Packet-filtering firewall - Examines individual packets based on rules (IP addresses, ports, protocols), operates at network layer, fast but limited intelligence. (2) Stateful inspection firewall (stateful packet filtering) - Tracks connection states and context, remembers previous packets, more intelligent than basic filtering. (3) Proxy firewall (application gateway) - Intercepts and analyzes application-layer traffic, acts as intermediary between internal and external networks, can understand specific protocols (HTTP, FTP, SMTP). Encryption is a security mechanism, not a firewall. Other security functions: (1) VPN (Virtual Private Network) - Creates encrypted tunnels, (2) IDS/IPS (Intrusion Detection/Prevention System) - Monitors for attacks, (3) DLP (Data Loss Prevention) - Prevents data leakage. Modern firewalls: (1) Next-Generation Firewalls (NGFW) - Combine multiple approaches, deep packet inspection, (2) Cloud firewalls - For cloud environments, (3) Endpoint firewalls - Software firewalls on individual devices. Firewalls work at different levels: Layer 3-4 (network layer firewalls) or Layer 7 (application firewalls). The question tests understanding that encryption is complementary security, not a firewall classification.",
    "chapter": "Chapter 5: Network & Security",
    "difficulty": "medium",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 31,
    "question": "What are the basic limitations of finite state machine?",
    "options": [
      "It cannot remember grammar for a language",
      "It cannot remember arbitrarily large amount of information",
      "It cannot remember language generated from a grammar",
      "It cannot remember state transitions"
    ],
    "correct_answer": "It cannot remember arbitrarily large amount of information",
    "hint": "FSM has a fixed, finite number of states. What does this fundamental limitation prevent?",
    "explanation": "The basic limitation of finite state machines is that they cannot remember arbitrarily large amounts of information. FSM has: (1) Fixed, finite number of states - Defined at design time, (2) Limited memory - Only the current state is remembered, (3) No stack or unbounded storage - Cannot push/pop arbitrary amounts of data. This fundamental limitation means FSMs: (1) Cannot parse context-free languages (like balanced parentheses), (2) Cannot count unbounded repetitions, (3) Cannot match arbitrarily nested structures. Examples of what FSMs cannot do: (1) Recognize anbn (equal number of a's followed by b's), (2) Match nested parentheses, (3) Parse programming language expressions with nesting. Formal language theory: (1) Regular languages - Recognized by FSMs, (2) Context-free languages - Require push-down automata (add stack), (3) Recursively enumerable languages - Require Turing machines. To overcome this, we use: (1) Push-down automata (add one stack), (2) Turing machines (add unlimited tape), (3) Practical alternatives - Compiler theory, parsing techniques. This limitation is why real parsing requires more powerful machines than FSMs. Application implications: (1) Network protocols - Can use FSMs, (2) Programming language compilation - Need more powerful machines, (3) Lexical analysis - FSMs sufficient, (4) Syntax analysis - Need push-down automata or more.",
    "chapter": "Chapter 6: Theory, Computation & Graphics",
    "difficulty": "medium",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 32,
    "question": "Which of the following Machine is specific for Context free grammar?",
    "options": [
      "Finite state automata",
      "Push down automata",
      "Linear bounded automata",
      "Turing Machine"
    ],
    "correct_answer": "Push down automata",
    "hint": "Context-free grammars need the ability to remember nested structures. What machine has a stack?",
    "explanation": "Push-down automata (PDA) is the specific machine for context-free grammars (CFG). PDA characteristics: (1) Adds a stack to FSM - Can store and retrieve unlimited information (within bounds of problem), (2) Recognizes context-free languages, (3) Useful for parsing programming languages. Automata hierarchy and languages: (1) FSM - Recognizes Regular languages, no memory, (2) PDA - Recognizes Context-free languages, has stack, (3) Linear Bounded Automata - Recognizes Context-sensitive languages, limited tape, (4) Turing Machine - Recognizes Recursively enumerable languages, unlimited tape. Why PDA for CFG: (1) Stack allows matching nested structures (parentheses, brackets), (2) Can parse recursive grammars, (3) Can recognize patterns like anbn (equal a's then b's), (4) Directly corresponds to grammar derivation. Practical applications: (1) Compiler parsing - Use PDA for syntax analysis, (2) Expression evaluation - Parentheses matching, (3) Programming language design - CFG describes language syntax. PDA implementation: (1) Scan input, (2) Push/pop from stack based on input and current state, (3) Accept if input consumed and stack in correct state. Formal definition: PDA = (Q, Σ, Γ, δ, q0, Z0, F) where Q = states, Σ = input alphabet, Γ = stack alphabet, δ = transition function, q0 = initial state, Z0 = initial stack symbol, F = final states.",
    "chapter": "Chapter 6: Theory, Computation & Graphics",
    "difficulty": "difficult",
    "marks": 1,
    "source": "NEC Official Model Questions"
  },
  {
    "id": 33,
    "question": "Turing machine (TM) is more powerful than FSM (Finite State Machine) because",
    "options": [
      "tape movement is confined to one direction",
      "it has no finite state",
      "it has the capability to remember arbitrarily long sequences of input symbols",
      "it has finite state"
    ],
    "correct_answer": "it has the capability to remember arbitrarily long sequences of input symbols",
    "hint": "Turing machines have unlimited memory through an infinite tape. What advantage does this provide?",
    "explanation": "Turing machines are more powerful than FSMs because they have the capability to remember arbitrarily long sequences of input symbols through an unlimited tape. Key differences: (1) FSM - Fixed number of states, limited memory, (2) Turing Machine - States plus unlimited tape, can store and retrieve any amount of information. TM advantages: (1) Infinite tape acts as unlimited memory - Can move back and forth on tape, (2) Can solve undecidable problems that FSMs cannot, (3) Can simulate any algorithm (Church-Turing thesis), (4) Can implement arbitrary computational processes. TM capabilities: (1) Recognize recursively enumerable languages, (2) Compute any computable function, (3) Model any effective procedure. The tape allows: (1) Multiple passes through data, (2) Storage of intermediate results, (3) Complex pattern matching and computation. Incorrect options analysis: (1) \"tape movement confined to one direction\" - TM can move left or right, (2) \"has no finite state\" - TM has states, just with unlimited memory, (3) \"has finite state\" - Both have states. The power comes from unlimited memory (tape), not from the state structure. Practical implications: (1) TMs are theoretical model for computation, (2) Real computers approximate TMs (bounded tape = memory), (3) Some problems are computationally undecidable (halting problem). The TM model is fundamental to computer science theory.",
    "chapter": "Chapter 6: Theory, Computation & Graphics",
    "difficulty": "difficult",
    "marks": 1,
    "source": "NEC Official Model Questions"
  }
]
